{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageDraw\n",
    "from IPython.display import display\n",
    "import face_recognition\n",
    "import numpy as np\n",
    "from sklearn import svm\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encodings = []\n",
    "names = []\n",
    "def face_recognize(dir=\"training\"):\n",
    "    # Training the SVC classifier\n",
    "    # The training data would be all the \n",
    "    # face encodings from all the known \n",
    "    # images and the labels are their names\n",
    "      \n",
    "    # Training directory\n",
    "    if dir[-1]!='/':\n",
    "        dir += '/'\n",
    "    train_dir = os.listdir(dir)\n",
    "    for person in train_dir:\n",
    "        pix = os.listdir(dir + person)\n",
    "  \n",
    "        # Loop through each training image for the current person\n",
    "        for person_img in pix:\n",
    "            face = face_recognition.load_image_file(\n",
    "                dir + person + \"/\" + person_img)\n",
    "            face_bounding_boxes = face_recognition.face_locations(face)\n",
    "  \n",
    "            # If training image contains exactly one face\n",
    "            if len(face_bounding_boxes) == 1:\n",
    "                face_enc = face_recognition.face_encodings(face)[0]\n",
    "                # Add face encoding for current image \n",
    "                # with corresponding label (name) to the training data\n",
    "                encodings.append(face_enc)\n",
    "                names.append(person)\n",
    "            else:\n",
    "                print(person + \"/\" + person_img + \" can't be used for training\")\n",
    "face_recognize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = svm.SVC(gamma ='scale')\n",
    "clf.fit(encodings, names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image = face_recognition.load_image_file(\"family.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_locations = face_recognition.face_locations(test_image)\n",
    "no = len(face_locations)\n",
    "print(\"Number of faces detected: \", no)\n",
    "print(face_locations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Found:\")\n",
    "for i in range(no):\n",
    "    test_image_enc = face_recognition.face_encodings(test_image)[i]\n",
    "    print(test_image_enc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cx_Oracle\n",
    "\n",
    "dsn_tns = cx_Oracle.makedsn('DESKTOP-7HUU5CV', '1521', service_name='XE') # if needed, place an 'r' before any parameter in order to address special characters such as '\\'.\n",
    "conn = cx_Oracle.connect(user=r'gshri2311', password='shri2311', dsn=dsn_tns) # if needed, place an 'r' before any parameter in order to address special characters such as '\\'. For example, if your user name contains '\\', you'll need to place 'r' before the user name: user=r'User Name'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask import Flask\n",
    "app = Flask(__name__)\n",
    "\n",
    "@app.route('/<name>')  \n",
    "def home(name):  \n",
    "    return \"hello,\"+name;  \n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(host='0.0.0.0',port=\"5000\", debug=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor = conn.cursor()\n",
    "cursor.execute(\"CREATE TABLE test1 (name VARCHAR(255), address VARCHAR(255))\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor.execute(\"insert into test(name , address) values('hi','hello')\")\n",
    "cursor.execute(\"select * from test\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in cursor.fetchall():\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import ImageChops # $ pip install pillow\n",
    "from pyscreenshot import grab # $ pip install pyscreenshot\n",
    "\n",
    "im = grab()\n",
    "while True: # http://effbot.org/zone/pil-comparing-images.htm\n",
    "    diff = ImageChops.difference(grab(), im)\n",
    "    bbox = diff.getbbox()\n",
    "    if bbox is not None: # exact comparison\n",
    "        break\n",
    "\n",
    "print(\"bounding box of non-zero difference: %s\" % (bbox,))\n",
    "# superimpose the inverted image and the difference\n",
    "ImageChops.screen(ImageChops.invert(im.crop(bbox)), diff.crop(bbox)).show()\n",
    "input(\"Press Enter to exit\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install pyautogui"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the required packages\n",
    "import pyautogui\n",
    "import cv2\n",
    "import numpy as np\n",
    "from skimage.measure import compare_ssim as ssim\n",
    "\n",
    "prev_frame = None\n",
    "# Specify resolution\n",
    "resolution = (1920, 1080)\n",
    "\n",
    "# Specify video codec\n",
    "codec = cv2.VideoWriter_fourcc(*\"XVID\")\n",
    "\n",
    "# Specify name of Output file\n",
    "filename = \"Recording.avi\"\n",
    "\n",
    "# Specify frames rate. We can choose any\n",
    "# value and experiment with it\n",
    "fps = 60.0\n",
    "\n",
    "\n",
    "# Creating a VideoWriter object\n",
    "out = cv2.VideoWriter(filename, codec, fps, resolution)\n",
    "\n",
    "# Create an Empty window\n",
    "cv2.namedWindow(\"Live\", cv2.WINDOW_NORMAL)\n",
    "\n",
    "# Resize this window\n",
    "cv2.resizeWindow(\"Live\", 480, 270)\n",
    "\n",
    "while True:\n",
    "\t# Take screenshot using PyAutoGUI\n",
    "\timg = pyautogui.screenshot()\n",
    "    simlarityIndex = ssim(prev_frame, img)\n",
    "    \n",
    "    prev_frame=img\n",
    "    \n",
    "    print(simlarityIndex)\n",
    "\n",
    "\t# Convert the screenshot to a numpy array\n",
    "\tframe = np.array(img)\n",
    "\n",
    "\t# Convert it from BGR(Blue, Green, Red) to\n",
    "\t# RGB(Red, Green, Blue)\n",
    "\tframe = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "\t# Write it to the output file\n",
    "\tout.write(frame)\n",
    "\t\n",
    "\t# Optional: Display the recording screen\n",
    "\tcv2.imshow('Live', frame)\n",
    "\t\n",
    "\t# Stop recording when we press 'q'\n",
    "\tif cv2.waitKey(1) == ord('q'):\n",
    "\t\tbreak\n",
    "\n",
    "# Release the Video writer\n",
    "out.release()\n",
    "\n",
    "# Destroy all windows\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "# Compute the frame difference\n",
    "def frame_diff(prev_frame, cur_frame, next_frame):\n",
    "    # Absolute difference between current frame and next frame\n",
    "    diff_frames1 = cv2.absdiff(next_frame, cur_frame)\n",
    "\n",
    "    # Absolute difference between current frame and # previous frame\n",
    "    diff_frames2 ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import requests\n",
    "import json\n",
    "import cv2\n",
    "\n",
    "addr = 'http://192.168.43.34:5000'\n",
    "test_url = addr + '/api/test'\n",
    "\n",
    "# prepare headers for http request\n",
    "content_type = 'image/jpeg'\n",
    "headers = {'content-type': content_type}\n",
    "\n",
    "img = cv2.imread('shriram.jpg')\n",
    "# encode image as jpeg\n",
    "_, img_encoded = cv2.imencode('.jpg', img)\n",
    "# send http request with image and receive response\n",
    "response = requests.post(test_url, data=img_encoded.tostring(), headers=headers)\n",
    "# decode response\n",
    "print(json.loads(response.text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask import Flask, request, Response\n",
    "import jsonpickle\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "\n",
    "# Initialize the Flask application\n",
    "app = Flask(__name__)\n",
    "\n",
    "@app.route('/')\n",
    "def test1():\n",
    "    return \"working\"\n",
    "# route http posts to this method\n",
    "@app.route('/api/test', methods=['POST'])\n",
    "def test():\n",
    "    r = request\n",
    "    # convert string of image data to uint8\n",
    "    nparr = np.fromstring(r.data, np.uint8)\n",
    "    # decode image\n",
    "    img = cv2.imdecode(nparr, cv2.IMREAD_COLOR)\n",
    "    cv2.imshow('HelloWorld', img)\n",
    "    cv2.waitKey(0) \n",
    "    cv2.destroyWindow('HelloWorld')\n",
    "\n",
    "    \n",
    "    # do some fancy processing here....\n",
    "\n",
    "    # build a response dict to send back to client\n",
    "    response = {'message': 'image received. size={}x{}'.format(img.shape[1], img.shape[0])\n",
    "                }\n",
    "    # encode response using jsonpickle\n",
    "    response_pickled = jsonpickle.encode(response)\n",
    "\n",
    "    return Response(response=response_pickled, status=200, mimetype=\"application/json\")\n",
    "\n",
    "\n",
    "# start flask app\n",
    "app.run(host=\"0.0.0.0\", port=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import face_recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shriram = face_recognition.load_image_file(\"shriram.jpg\")\n",
    "shriram_face_encoding = face_recognition.face_encodings(shriram)[0]\n",
    "rani = face_recognition.load_image_file(\"rani.jpg\")\n",
    "rani_face_encoding = face_recognition.face_encodings(rani)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "known_face_encodings = [\n",
    "    shriram_face_encoding,\n",
    "    rani_face_encoding\n",
    "]\n",
    "known_face_names = [\n",
    "    \"Shriram\",\n",
    "    \"Amma\"\n",
    "]\n",
    "print('Learned encoding for', len(known_face_encodings), 'images.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
